---
title: "Visiting 31 Colleges"
author: "Lathan Liou"
date: "2/12/2020"
output: pdf_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rjson)
library(readxl)
library(ggmap)
library(ggforce)

register_google(key = "AIzaSyC43hGY_yp_oZqkZf7zGXeCu9ObmeSLi-s")

distmat <- fromJSON(file= "/Users/lathanliou/Desktop/Academic/DataProjects/cambridge-colleges/cambridge-colleges.json")
distances <- distmat %>% as.data.frame()
coords <- read_excel("/Users/lathanliou/Desktop/Academic/DataProjects/cambridge-colleges/cambridge-colleges-coords.xlsx")
```

# The Motivation
I remember when I was looking at the different colleges at Cambridge, I didn't really have a good idea of what each of them looked like, since there was no video that took a tour of all of them. So, I decided that I wanted to make a video where I visit each college and film a mini virtual tour around. But, it's not like the colleges are all close to one another. Some are quite far. So, I want to find the most efficient way to travel to all the colleges by foot/bike. There are 31 total colleges in Cambridge, and they're spread all across the city. You can roughly categorize their location as either being in the center of the city, on the hill, or by the river. 

# Looking at the Spatial Distribution of Colleges
The first type of data I want to get is the latitude and longitude data. I can use Google's Geocoding API, but I can only request one address at a time. That's too bad. Guess I'll have to do it manually and put the latitudes and longitudes in a spreadsheet. Note that you need an API key to be able to make query requests using this API. To plot, I'm enabling Google's Maps Static API. For anyone having issues, check out this thread for good debugging techniques when using Google APIs (https://github.com/dkahle/ggmap/issues/262)

```{r}
cambridgemap <- qmap("cambridge, england", zoom = 14, color = "bw", legend = "topleft")

collegemap <- cambridgemap + 
  geom_point(data = coords, aes(x = lon, y = lat, colour = cat)) +
  geom_text(data = coords, aes(x = lon, y = lat, label = name), hjust=0, vjust=-0.5, size = 2)

collegemap
```

# Calculating Minimum Distance
It seems that it might be worth tackling this challenge in clusters. So one way to approach this problem is to think about it like the Traveling Salesman Problem. Basically, it poses the question of how to find the most efficient route through various points. To solve this problem, we are using an algorithm called \textbf{simulated annealing}. The idea behind simulated annealing is that we choose a random path, and we change the path by switching two cities. If this new path has a shorter path length, then we keep it for sure. Otherwise, if the new path has a larger path length, we might end up keeping it anyway with some probability. This allows the salesman to take uphill steps in our minimization problem with some probability in the hopes that the salesman can discover more optimal minima. We obtain our random walk probability from the Metropolis Hastings result which we said was
$$P(\text{take} \> y | \text{get} \> x) = \min \{ 1, \frac{f(y)}{f(x)} \}$$
assuming we were sampling $g$ from a uniform. This probability is defined as
$$e^{\frac{h(x)-h(y)}{T}}$$

A \textbf{cooling schedule} defines how wide across the space the salesman can explore his paths as well as how many times he can explore paths. We start at high temperatures with a low number of iterations such that the salesman can consider many paths, even those that are not close to the global minimum at all. As we cool (temperature $\rightarrow 0$), our probability of staying at non-optimal paths also approaches $0$, since e's exponent is going towards negative infinity. However, at the best minimum path the salesman finds, our probability approaches 1 because $h(x)$ is close to $h(y)$ so e's exponent is going towards $0$. This is equivalent to the salesman locking in on what he thinks is the best path and not considering other paths. 

## Obtain Most Efficient Path From Coordinate Data Alone

So, here I present code for how to perform simulated annealing.
```{r}
create_distance_matrix <- function(x) {
  d <- as.matrix(dist(x))
}

calculate_path_length <- function(d, path) {
  length <- 0
  for (i in 1:(length(path)-1)) { #subtract 1 because there are n-1 paths for n cities
    length <- length + d[path[i], path[i+1]] # add lengths of paths between consecutive cities
  }
  length <- length + d[path[1], path[i+1]] #add path back to starting point
  return(length)
}

perform_simulated_annealing <- function(path, tau, distance_matrix){
  k <- 1
  path.dist <- c()
  n.tau <- seq(100, 10000, len = length(tau))
  path_length <- calculate_path_length(distance_matrix, path)
  for (i in 1:length(tau)){
    for (j in 1:n.tau[i]){
      swap <- sample(1:length(path), 2) #randomly select two points to swap
      new.path <- path
      #manually do the swap by switching the indices of the path
      new.path[swap] <- path[c(swap[2], swap[1])] 
      new_path_length <- calculate_path_length(distance_matrix, new.path)
      #if we get a new path length that is smaller than the old path length, we save it
      if (runif(1) < exp(path_length - new_path_length/tau[i])) {
        path <- new.path 
        new_path_length <- path_length 
      }
      path.dist[k] <- path_length
      k <- k + 1
    }
  }
}
```

I think it'd be interesting to see whether what the most efficient paths are per cluster vs the most efficient path across all the colleges. 
```{r}
PATH <- 1:31
PATH_CENTER <- 1:17
PATH_HILL <- 1:6
PATH_RIVER <- 1:5

distances <- create_distance_matrix(coords %>% select(lat, lon))
distances_center <- create_distance_matrix(coords %>% filter(cat == "center") %>%
                                             select(lat, lon))
distances_river <- create_distance_matrix(coords %>% filter(cat == "river") %>%
                                            select(lat, lon))
distances_hill <- create_distance_matrix(coords %>% filter(cat == "hill") %>%
                                           select(lat, lon))

TAU <- c(1000,500,100,50,25,20,10,5,2,1,.1,.01,.001,.0001)

perform_simulated_annealing(PATH, TAU, distances)
perform_simulated_annealing(PATH_CENTER, TAU, distances_center)
perform_simulated_annealing(PATH_HILL, TAU, distances_hill)
perform_simulated_annealing(PATH_RIVER, TAU, distances_river)
```

If we wanted to see the progress of the simulated annealing algorithm, we can plot it. We also should plot it to see if the algorithm reached an adequate minimum
```{r}
plot(path.dist, type = "l")
```

Otherwise, let's plot the most efficient paths.
```{r}
# Generate plot
center_coords <- coords %>%
  filter(cat == "center")
hill_coords <- coords %>%
  filter(cat == "hill")
river_coords <- coords %>%
  filter(cat == "river")

for(i in 1:length(PATH_CENTER)){
    collegemap <- collegemap + 
    geom_segment(x = center_coords$lon[PATH_CENTER[i]], 
               y = center_coords$lat[PATH_CENTER[i]], 
               xend = center_coords$lon[PATH_CENTER[i+1]], 
               yend = center_coords$lat[PATH_CENTER[i+1]],
               colour = "red")
}

for(i in 1:length(PATH_HILL)){
    collegemap <- collegemap + 
    geom_segment(x = hill_coords$lon[PATH_HILL[i]], 
               y = hill_coords$lat[PATH_HILL[i]], 
               xend = hill_coords$lon[PATH_HILL[i+1]], 
               yend = hill_coords$lat[PATH_HILL[i+1]],
               colour = "green")
}

for(i in 1:length(PATH_RIVER)){
  collegemap <- collegemap + 
    geom_segment(x = river_coords$lon[PATH_RIVER[i]], 
               y = river_coords$lat[PATH_RIVER[i]], 
               xend = river_coords$lon[PATH_RIVER[i+1]], 
               yend = river_coords$lat[PATH_RIVER[i+1]],
               colour = "purple")
}

collegemap
```

Ooh, so the center one doesn't look too great. For example, it missed that St. Catharine's and Corpus Christi are right next to each other and instead joined them on a consecutive path, which is sensible to humans. Other things that to note is that for example, I didn't specify in the model what I want my final destination to be. So for visiting the hill colleges, it might make sense that I'd want to end closer to where I live, which is in the city center. 

## Using a Distance Matrix
Let's see if we can try one more data-motivated method to obtain our most efficient path before we resort to good old-fashioned human eyeballing.

To obtain a distance matrix, I'm using Google's Distance Matrix API. So the form for the query request is 

`maps.googleapis.com/maps/api/distancematrix/json?units=imperial&origins=[ORIGINS]&destinations=[DESTS]&key=[YOUR API KEY]&mode=bicycling`

where you can specify your origin as either a string address, latitutde/longitude coordinates, or a place ID. 

So, I go through the process of writing all of the colleges in my search query. I can specify multiple origins, and I'll put as my destination Christ's College, which is my own college. Once I have the full query, I can run it, and then save the results as a JSON file. 

```{r}
distance_df <- as.data.frame(distmat)
distance_df2 <- distance_df %>%
  select(starts_with("rows.elements.duration.text"))
```